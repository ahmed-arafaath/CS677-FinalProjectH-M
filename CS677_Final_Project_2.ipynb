{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6040ab1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SAJIN~1.LAP\\AppData\\Local\\Temp/ipykernel_11272/1807182953.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Scikit-Learn ≥0.20 is required\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;34m\"0.20\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m from .utils._tags import (\n\u001b[0;32m     19\u001b[0m     \u001b[0m_DEFAULT_TAGS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\class_weight.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_deprecate_positional_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcontextlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPositiveSpectrumWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlsqr\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msparse_lsqr\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMaskedArray\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_MaskedArray\u001b[0m  \u001b[1;31m# TODO: remove in 1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \"\"\"\n\u001b[1;32m--> 391\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#       instead of `git blame -Lxxx,+x`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m from ._distn_infrastructure import (entropy, rv_discrete, rv_continuous,\n\u001b[0m\u001b[0;32m      9\u001b[0m                                     rv_frozen)\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# for root finding for continuous distribution ppf, and max likelihood estimation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_nnls\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnnls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_basinhopping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbasinhopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_linprog\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinprog_verbose_callback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_lsap\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear_sum_assignment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_differentialevolution\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdifferential_evolution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linprog.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_linprog_simplex\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_linprog_simplex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_linprog_rs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_linprog_rs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_linprog_highs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_linprog_highs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m from ._linprog_doc import (_linprog_highs_doc, _linprog_ip_doc,\n\u001b[0;32m     27\u001b[0m                            \u001b[0m_linprog_rs_doc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_linprog_simplex_doc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mpath_stats\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from typing import Dict, Text\n",
    "from tensorflow import keras\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import tensorflow_recommenders as tfrs\n",
    "try:\n",
    "    if not tf.config.list_physical_devices('GPU'):\n",
    "        assert tf.__version__ >= \"2.0\"\n",
    "        print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "        if IS_COLAB:\n",
    "            print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "        if IS_KAGGLE:\n",
    "            print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "except:\n",
    "    if not tf.test.is_gpu_available():\n",
    "        assert tf.__version__ >= \"2.0\"\n",
    "        print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "        if IS_COLAB:\n",
    "            print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "        if IS_KAGGLE:\n",
    "            print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "try:\n",
    "    if not tf.config.list_physical_devices('GPU'):\n",
    "        tf.random.set_seed(42)\n",
    "    else:\n",
    "        tf.random.set_random_seed(42)\n",
    "except:\n",
    "    if not tf.test.is_gpu_available():\n",
    "        tf.random.set_seed(42)\n",
    "    else:\n",
    "        tf.random.set_random_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af88b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_f(item):\n",
    "    item=str(item)\n",
    "    tem=len(item)\n",
    "    if(len(item)<10):\n",
    "        item=item.zfill(10)\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f820ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_train = pd.read_csv('h-and-m-personalized-fashion-recommendations/transactions_train.csv',dtype={'customer_id': str,'article_id':str})\n",
    "trans_train['quantity']=1\n",
    "trans_train = trans_train[trans_train['t_dat'] >'2020-06-15']\n",
    "articles= pd.read_csv('h-and-m-personalized-fashion-recommendations/articles.csv',dtype={'article_id': str,'product_code':str})\n",
    "customers = pd.read_csv('h-and-m-personalized-fashion-recommendations/customers.csv',dtype={'customer_id':str})\n",
    "master_df = trans_train[['customer_id','article_id','t_dat']].astype(str)\n",
    "master_df['article_id']=master_df['article_id'].apply(zero_f)\n",
    "master_df['quantity'] = trans_train['quantity'].astype(float)\n",
    "masterdf = master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = masterdf.groupby(['customer_id', 'article_id','t_dat'])[ 'quantity'].sum().reset_index()\n",
    "interactions['t_dat']=pd.to_datetime(interactions['t_dat'])\n",
    "interactions=interactions.groupby([pd.Grouper(key=\"customer_id\"),pd.Grouper(key=\"article_id\"),pd.Grouper(key=\"t_dat\",freq=\"1M\")])['quantity'].sum().reset_index()\n",
    "interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda497d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.sort_values(by='t_dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9251ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.sort_values(by='t_dat').tail(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = interactions[interactions['t_dat']<='2020-09-18']\n",
    "valid=interactions[(interactions['t_dat'] >'2020-09-18')& (interactions['t_dat'] <='2020-09-25')]\n",
    "test = interactions[interactions['t_dat'] >'2020-09-25']\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dc383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4546de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bfc871",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(dict(train[['customer_id','article_id','quantity']])).shuffle(1_000_000).batch(256).cache()\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices(dict(valid[['customer_id','article_id','quantity']])).batch(256).cache()\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(dict(test[['customer_id','article_id','quantity']])).batch(256).cache()\n",
    "items_dict = articles[['article_id']].drop_duplicates()\n",
    "customer_dict=customers[['customer_id']].drop_duplicates()\n",
    "items_dict = {name: np.array(value) for name, value in items_dict.items()}\n",
    "customer_dict={name:np.array(value) for name,value in customer_dict.items()}\n",
    "customers=tf.data.Dataset.from_tensor_slices(customer_dict)\n",
    "items = tf.data.Dataset.from_tensor_slices(items_dict)\n",
    "items = items.map(lambda x: x['article_id'])\n",
    "customers=customers.map(lambda x: x['customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f11f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get unique item and user id's as a lookup table\n",
    "unique_items = np.unique(np.concatenate(list(items.batch(1_000))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(customers.batch(1_000))))\n",
    "\n",
    "# Randomly shuffle data and split between train and test.\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b106844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "def my_positive_weights(weights): # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87194fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        ## embed user id from unique_user_ids\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, 64),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.user_embedding(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408aa3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        max_tokens = 10_000\n",
    "\n",
    "        ## embed title from unique_item_titles\n",
    "        self.title_embedding = tf.keras.Sequential([\n",
    "                      tf.keras.layers.StringLookup(\n",
    "                          vocabulary=unique_items, mask_token=None),\n",
    "                      tf.keras.layers.Embedding(len(unique_items) + 1, 64)])\n",
    "\n",
    "        ## processing text features: item title vectorizer (see self.title_vectorizer)\n",
    "        self.title_vectorizer = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=max_tokens)\n",
    "\n",
    "        ## we apply title vectorizer to items\n",
    "        self.title_text_embedding = tf.keras.Sequential([\n",
    "                              self.title_vectorizer,\n",
    "                              tf.keras.layers.Embedding(max_tokens, 64, mask_zero=True),\n",
    "                              tf.keras.layers.GlobalMaxPooling1D()])\n",
    "\n",
    "        self.title_vectorizer.adapt(items)\n",
    "\n",
    "    def call(self, titles):\n",
    "        return tf.concat([\n",
    "            self.title_embedding(titles),\n",
    "            self.title_text_embedding(titles),], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ec28a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateModel(tfrs.models.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        ## query model is user model\n",
    "        self.query_model = tf.keras.Sequential([\n",
    "                          UserModel(),\n",
    "                          tf.keras.layers.Dense(256,activation=\"relu\",kernel_initializer='he_normal',use_bias=False),\n",
    "                          tf.keras.layers.BatchNormalization(),\n",
    "                          tf.keras.layers.Dropout(0.3),\n",
    "                          tf.keras.layers.Dense(128,activation=\"relu\",kernel_initializer='he_normal',use_bias=False),\n",
    "                          tf.keras.layers.BatchNormalization(),\n",
    "                          tf.keras.layers.Dropout(0.3),\n",
    "                          tf.keras.layers.Dense(64,activation=\"relu\",kernel_initializer='he_normal',use_bias=False),\n",
    "                          tf.keras.layers.BatchNormalization(),\n",
    "                          tf.keras.layers.Dropout(0.3),\n",
    "                          tf.keras.layers.Dense(32,kernel_regularizer=my_l1_regularizer,kernel_constraint=my_positive_weights)])\n",
    "        \n",
    "        ## candidate model is the item model\n",
    "        self.candidate_model = tf.keras.Sequential([\n",
    "                              ItemModel(),\n",
    "                              tf.keras.layers.Dense(256,activation=\"relu\",kernel_initializer='he_normal',use_bias=False),\n",
    "                              tf.keras.layers.BatchNormalization(),\n",
    "                              keras.layers.Dropout(0.3),\n",
    "                              tf.keras.layers.Dense(128,activation=\"relu\",kernel_initializer='he_normal',use_bias=False),\n",
    "                              tf.keras.layers.BatchNormalization(),\n",
    "                              tf.keras.layers.Dropout(0.3),\n",
    "                              tf.keras.layers.Dense(64,activation=\"relu\",kernel_initializer='he_normal',use_bias=False),\n",
    "                              tf.keras.layers.BatchNormalization(),\n",
    "                              tf.keras.layers.Dropout(0.3),\n",
    "                              tf.keras.layers.Dense(32,kernel_regularizer=my_l1_regularizer,kernel_constraint=my_positive_weights)])\n",
    "        \n",
    "        ## retrieval task, choose metrics\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "                    metrics=tfrs.metrics.FactorizedTopK(\n",
    "                        candidates=items.batch(128).map(self.candidate_model),),)\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        # We only pass the user id and timestamp features into the query model. This\n",
    "        # is to ensure that the training inputs would have the same keys as the\n",
    "        # query inputs. Otherwise the discrepancy in input structure would cause an\n",
    "        # error when loading the query model after saving it.\n",
    "        \n",
    "        query_embeddings = self.query_model(features[\"customer_id\"])\n",
    "        \n",
    "        item_embeddings = self.candidate_model(features[\"article_id\"])\n",
    "\n",
    "        return self.task(query_embeddings, item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcfe736",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CandidateModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "model.fit(train_ds,validation_data=valid_ds,epochs=3,batch_size=128)\n",
    "model.evaluate(test_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6f841",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = tfrs.layers.factorized_top_k.BruteForce(model.query_model)\n",
    "index.index_from_dataset(items.batch(100).map(lambda items: (items,model.candidate_model(items))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8357bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, titles = index(np.array([\"000231cc9af9e58ab4edc66fbd61da921b144ba85bc1c00d0ae2309531e4c210\"]), k=3)\n",
    "print(f\"Top recommendations: {titles[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4fbeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, titles = index(np.array([\"000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318\"]), k=12)\n",
    "print(f\"Top recommendations: {titles[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b5449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(e):\n",
    "    return e.decode('UTF-8')\n",
    "def run_f(item):\n",
    "    _, titles = index(tf.constant([item]),k=12)\n",
    "    t = np.array(titles[0])\n",
    "    vfunc = np.vectorize(decoder)\n",
    "    l = vfunc(t)\n",
    "    l = \" \".join(l)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file = pd.read_csv('h-and-m-personalized-fashion-recommendations/sample_submission.csv',dtype={'customer_id': str})\n",
    "sub_cust = submission_file[\"customer_id\"]\n",
    "sub_df = pd.DataFrame(columns=['Customer_Id', 'Article_Id'])\n",
    "submission_file[\"prediction\"] = submission_file['customer_id'].progress_apply(run_f)\n",
    "submission_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b66c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e90c31c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
