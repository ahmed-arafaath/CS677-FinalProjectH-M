{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405e34ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from typing import Dict, Text\n",
    "from tensorflow import keras\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import tensorflow_recommenders as tfrs\n",
    "try:\n",
    "    if not tf.config.list_physical_devices('GPU'):\n",
    "        assert tf.__version__ >= \"2.0\"\n",
    "        print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "        if IS_COLAB:\n",
    "            print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "        if IS_KAGGLE:\n",
    "            print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "except:\n",
    "    if not tf.test.is_gpu_available():\n",
    "        assert tf.__version__ >= \"2.0\"\n",
    "        print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "        if IS_COLAB:\n",
    "            print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "        if IS_KAGGLE:\n",
    "            print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "try:\n",
    "    if not tf.config.list_physical_devices('GPU'):\n",
    "        tf.random.set_seed(42)\n",
    "    else:\n",
    "        tf.random.set_random_seed(42)\n",
    "except:\n",
    "    if not tf.test.is_gpu_available():\n",
    "        tf.random.set_seed(42)\n",
    "    else:\n",
    "        tf.random.set_random_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dfcb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_f(item):\n",
    "    item=str(item)\n",
    "    tem=len(item)\n",
    "    if(len(item)<10):\n",
    "        item=item.zfill(10)\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b54c2c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0663713001</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0541518023</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0505221004</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0685687003</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0685687004</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id  article_id  quantity\n",
       "0  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  0663713001       1.0\n",
       "1  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  0541518023       1.0\n",
       "2  00007d2de826758b65a93dd24ce629ed66842531df6699...  0505221004       1.0\n",
       "3  00007d2de826758b65a93dd24ce629ed66842531df6699...  0685687003       1.0\n",
       "4  00007d2de826758b65a93dd24ce629ed66842531df6699...  0685687004       1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_train = pd.read_csv('h-and-m-personalized-fashion-recommendations/transactions_train.csv',dtype={'customer_id': str,'article_id':str})\n",
    "trans_train['quantity']=1\n",
    "master_df = trans_train[['customer_id','article_id','quantity']].astype(str)\n",
    "master_df['article_id']=master_df['article_id'].apply(zero_f)\n",
    "master_df['quantity'] = master_df['quantity'].astype(float)\n",
    "masterdf = master_df\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84618e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define interactions data and user data\n",
    "\n",
    "### interactions \n",
    "### here we create a reference table of the user , item, and quantity purchased\n",
    "interactions_dict = masterdf.groupby(['customer_id', 'article_id'])[ 'quantity'].sum().reset_index()\n",
    "\n",
    "## we tansform the table inta a dictionary , which then we feed into tensor slices\n",
    "# this step is crucial as this will be the type of data fed into the embedding layers\n",
    "interactions_dict = {name: np.array(value) for name, value in interactions_dict.items()}\n",
    "interactions = tf.data.Dataset.from_tensor_slices(interactions_dict)\n",
    "\n",
    "## we do similar step for item, where this is the reference table for items to be recommended\n",
    "items_dict = masterdf[['article_id']].drop_duplicates()\n",
    "items_dict = {name: np.array(value) for name, value in items_dict.items()}\n",
    "items = tf.data.Dataset.from_tensor_slices(items_dict)\n",
    "\n",
    "## map the features in interactions and items to an identifier that we will use throught the embedding layers\n",
    "## do it for all the items in interaction and item table\n",
    "## you may often get itemtype error, so that is why here i am casting the quantity type as float to ensure consistency\n",
    "interactions = interactions.map(lambda x: {\n",
    "    'customer_id' : x['customer_id'], \n",
    "    'article_id' : x['article_id'], \n",
    "    'quantity' : float(x['quantity']),\n",
    "\n",
    "})\n",
    "\n",
    "items = items.map(lambda x: x['article_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b56fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_item_titles = np.unique(np.concatenate(list(items.batch(1_000))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(interactions.batch(1_000_000).map(lambda x: x[\"customer_id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e083ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get unique item and user id's as a lookup table\n",
    "unique_item_titles = np.unique(np.concatenate(list(items.batch(1_000))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(interactions.batch(1_000_000).map(lambda x: x[\"customer_id\"]))))\n",
    "\n",
    "# Randomly shuffle data and split between train and test.\n",
    "tf.random.set_seed(42)\n",
    "shuffled = interactions.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "417a70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetailModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self, user_model, item_model):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.item_model: tf.keras.Model = item_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        \n",
    "        ### for retrieval model. we take top-k accuracy as metrics\n",
    "        metrics = tfrs.metrics.FactorizedTopK(candidates=items.batch(256).map(item_model))\n",
    "        \n",
    "        # define the task, which is retrieval                                    )    \n",
    "        task = tfrs.tasks.Retrieval(metrics=metrics)\n",
    "       \n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"customer_id\"])\n",
    "        # And pick out the movie features and pass them into the movie model,\n",
    "        # getting embeddings back.\n",
    "        positive_movie_embeddings = self.item_model(features[\"article_id\"])\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(user_embeddings, positive_movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5711d538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 109s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 7.5000e-05 - factorized_top_k/top_10_categorical_accuracy: 1.1250e-04 - factorized_top_k/top_50_categorical_accuracy: 6.2500e-04 - factorized_top_k/top_100_categorical_accuracy: 0.0012 - loss: 70367.5362 - regularization_loss: 0.0000e+00 - total_loss: 70367.5362\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 103s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.3750e-04 - factorized_top_k/top_10_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0011 - factorized_top_k/top_100_categorical_accuracy: 0.0018 - loss: 70359.1811 - regularization_loss: 0.0000e+00 - total_loss: 70359.1811\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 104s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.8750e-04 - factorized_top_k/top_10_categorical_accuracy: 3.7500e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0015 - factorized_top_k/top_100_categorical_accuracy: 0.0029 - loss: 70350.6982 - regularization_loss: 0.0000e+00 - total_loss: 70350.6982\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 105s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 3.6250e-04 - factorized_top_k/top_10_categorical_accuracy: 7.0000e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0024 - factorized_top_k/top_100_categorical_accuracy: 0.0046 - loss: 70341.9375 - regularization_loss: 0.0000e+00 - total_loss: 70341.9375\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 103s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 6.0000e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0011 - factorized_top_k/top_50_categorical_accuracy: 0.0040 - factorized_top_k/top_100_categorical_accuracy: 0.0068 - loss: 70332.7464 - regularization_loss: 0.0000e+00 - total_loss: 70332.7464\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 103s 10s/step - factorized_top_k/top_1_categorical_accuracy: 1.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 9.8750e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0019 - factorized_top_k/top_50_categorical_accuracy: 0.0062 - factorized_top_k/top_100_categorical_accuracy: 0.0106 - loss: 70322.9524 - regularization_loss: 0.0000e+00 - total_loss: 70322.9524\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 106s 11s/step - factorized_top_k/top_1_categorical_accuracy: 6.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0018 - factorized_top_k/top_10_categorical_accuracy: 0.0030 - factorized_top_k/top_50_categorical_accuracy: 0.0097 - factorized_top_k/top_100_categorical_accuracy: 0.0163 - loss: 70312.3778 - regularization_loss: 0.0000e+00 - total_loss: 70312.3778\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 105s 10s/step - factorized_top_k/top_1_categorical_accuracy: 1.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0029 - factorized_top_k/top_10_categorical_accuracy: 0.0049 - factorized_top_k/top_50_categorical_accuracy: 0.0149 - factorized_top_k/top_100_categorical_accuracy: 0.0245 - loss: 70300.7955 - regularization_loss: 0.0000e+00 - total_loss: 70300.7955\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 108s 11s/step - factorized_top_k/top_1_categorical_accuracy: 2.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0047 - factorized_top_k/top_10_categorical_accuracy: 0.0077 - factorized_top_k/top_50_categorical_accuracy: 0.0230 - factorized_top_k/top_100_categorical_accuracy: 0.0357 - loss: 70287.9510 - regularization_loss: 0.0000e+00 - total_loss: 70287.9510\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 109s 11s/step - factorized_top_k/top_1_categorical_accuracy: 5.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0076 - factorized_top_k/top_10_categorical_accuracy: 0.0124 - factorized_top_k/top_50_categorical_accuracy: 0.0336 - factorized_top_k/top_100_categorical_accuracy: 0.0507 - loss: 70273.5696 - regularization_loss: 0.0000e+00 - total_loss: 70273.5696\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 109s 11s/step - factorized_top_k/top_1_categorical_accuracy: 8.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0118 - factorized_top_k/top_10_categorical_accuracy: 0.0186 - factorized_top_k/top_50_categorical_accuracy: 0.0484 - factorized_top_k/top_100_categorical_accuracy: 0.0697 - loss: 70257.2741 - regularization_loss: 0.0000e+00 - total_loss: 70257.2741\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 107s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0171 - factorized_top_k/top_10_categorical_accuracy: 0.0270 - factorized_top_k/top_50_categorical_accuracy: 0.0662 - factorized_top_k/top_100_categorical_accuracy: 0.0926 - loss: 70238.6513 - regularization_loss: 0.0000e+00 - total_loss: 70238.6513\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 106s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0242 - factorized_top_k/top_10_categorical_accuracy: 0.0378 - factorized_top_k/top_50_categorical_accuracy: 0.0883 - factorized_top_k/top_100_categorical_accuracy: 0.1210 - loss: 70217.1719 - regularization_loss: 0.0000e+00 - total_loss: 70217.1719\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 105s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0024 - factorized_top_k/top_5_categorical_accuracy: 0.0321 - factorized_top_k/top_10_categorical_accuracy: 0.0504 - factorized_top_k/top_50_categorical_accuracy: 0.1144 - factorized_top_k/top_100_categorical_accuracy: 0.1553 - loss: 70192.1861 - regularization_loss: 0.0000e+00 - total_loss: 70192.1861\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 106s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0028 - factorized_top_k/top_5_categorical_accuracy: 0.0401 - factorized_top_k/top_10_categorical_accuracy: 0.0638 - factorized_top_k/top_50_categorical_accuracy: 0.1442 - factorized_top_k/top_100_categorical_accuracy: 0.1953 - loss: 70162.9141 - regularization_loss: 0.0000e+00 - total_loss: 70162.9141\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 106s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0028 - factorized_top_k/top_5_categorical_accuracy: 0.0469 - factorized_top_k/top_10_categorical_accuracy: 0.0778 - factorized_top_k/top_50_categorical_accuracy: 0.1773 - factorized_top_k/top_100_categorical_accuracy: 0.2377 - loss: 70128.3558 - regularization_loss: 0.0000e+00 - total_loss: 70128.3558\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 106s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0033 - factorized_top_k/top_5_categorical_accuracy: 0.0520 - factorized_top_k/top_10_categorical_accuracy: 0.0905 - factorized_top_k/top_50_categorical_accuracy: 0.2124 - factorized_top_k/top_100_categorical_accuracy: 0.2811 - loss: 70087.2919 - regularization_loss: 0.0000e+00 - total_loss: 70087.2919\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 109s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0558 - factorized_top_k/top_10_categorical_accuracy: 0.0992 - factorized_top_k/top_50_categorical_accuracy: 0.2461 - factorized_top_k/top_100_categorical_accuracy: 0.3259 - loss: 70038.1790 - regularization_loss: 0.0000e+00 - total_loss: 70038.1790\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 105s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0037 - factorized_top_k/top_5_categorical_accuracy: 0.0574 - factorized_top_k/top_10_categorical_accuracy: 0.1054 - factorized_top_k/top_50_categorical_accuracy: 0.2770 - factorized_top_k/top_100_categorical_accuracy: 0.3706 - loss: 69979.1016 - regularization_loss: 0.0000e+00 - total_loss: 69979.1016\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 108s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0040 - factorized_top_k/top_5_categorical_accuracy: 0.0582 - factorized_top_k/top_10_categorical_accuracy: 0.1077 - factorized_top_k/top_50_categorical_accuracy: 0.3045 - factorized_top_k/top_100_categorical_accuracy: 0.4107 - loss: 69907.6726 - regularization_loss: 0.0000e+00 - total_loss: 69907.6726\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 104s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0042 - factorized_top_k/top_5_categorical_accuracy: 0.0579 - factorized_top_k/top_10_categorical_accuracy: 0.1082 - factorized_top_k/top_50_categorical_accuracy: 0.3249 - factorized_top_k/top_100_categorical_accuracy: 0.4457 - loss: 69820.9432 - regularization_loss: 0.0000e+00 - total_loss: 69820.9432\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 103s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0046 - factorized_top_k/top_5_categorical_accuracy: 0.0574 - factorized_top_k/top_10_categorical_accuracy: 0.1072 - factorized_top_k/top_50_categorical_accuracy: 0.3381 - factorized_top_k/top_100_categorical_accuracy: 0.4749 - loss: 69715.3729 - regularization_loss: 0.0000e+00 - total_loss: 69715.3729\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 102s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0046 - factorized_top_k/top_5_categorical_accuracy: 0.0565 - factorized_top_k/top_10_categorical_accuracy: 0.1055 - factorized_top_k/top_50_categorical_accuracy: 0.3436 - factorized_top_k/top_100_categorical_accuracy: 0.4949 - loss: 69586.9602 - regularization_loss: 0.0000e+00 - total_loss: 69586.9602\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 104s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0049 - factorized_top_k/top_5_categorical_accuracy: 0.0558 - factorized_top_k/top_10_categorical_accuracy: 0.1034 - factorized_top_k/top_50_categorical_accuracy: 0.3423 - factorized_top_k/top_100_categorical_accuracy: 0.5058 - loss: 69431.8260 - regularization_loss: 0.0000e+00 - total_loss: 69431.8260\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 111s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0050 - factorized_top_k/top_5_categorical_accuracy: 0.0555 - factorized_top_k/top_10_categorical_accuracy: 0.1012 - factorized_top_k/top_50_categorical_accuracy: 0.3362 - factorized_top_k/top_100_categorical_accuracy: 0.5087 - loss: 69247.5149 - regularization_loss: 0.0000e+00 - total_loss: 69247.5149\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 115s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0050 - factorized_top_k/top_5_categorical_accuracy: 0.0558 - factorized_top_k/top_10_categorical_accuracy: 0.1000 - factorized_top_k/top_50_categorical_accuracy: 0.3283 - factorized_top_k/top_100_categorical_accuracy: 0.5057 - loss: 69033.9624 - regularization_loss: 0.0000e+00 - total_loss: 69033.9624\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 108s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0054 - factorized_top_k/top_5_categorical_accuracy: 0.0561 - factorized_top_k/top_10_categorical_accuracy: 0.0996 - factorized_top_k/top_50_categorical_accuracy: 0.3199 - factorized_top_k/top_100_categorical_accuracy: 0.5005 - loss: 68792.8395 - regularization_loss: 0.0000e+00 - total_loss: 68792.8395\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 117s 12s/step - factorized_top_k/top_1_categorical_accuracy: 0.0057 - factorized_top_k/top_5_categorical_accuracy: 0.0569 - factorized_top_k/top_10_categorical_accuracy: 0.0989 - factorized_top_k/top_50_categorical_accuracy: 0.3115 - factorized_top_k/top_100_categorical_accuracy: 0.4938 - loss: 68526.2656 - regularization_loss: 0.0000e+00 - total_loss: 68526.2656\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 125s 12s/step - factorized_top_k/top_1_categorical_accuracy: 0.0059 - factorized_top_k/top_5_categorical_accuracy: 0.0579 - factorized_top_k/top_10_categorical_accuracy: 0.0997 - factorized_top_k/top_50_categorical_accuracy: 0.3057 - factorized_top_k/top_100_categorical_accuracy: 0.4886 - loss: 68234.9006 - regularization_loss: 0.0000e+00 - total_loss: 68234.9006\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 116s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0064 - factorized_top_k/top_5_categorical_accuracy: 0.0587 - factorized_top_k/top_10_categorical_accuracy: 0.1009 - factorized_top_k/top_50_categorical_accuracy: 0.3013 - factorized_top_k/top_100_categorical_accuracy: 0.4856 - loss: 67916.3118 - regularization_loss: 0.0000e+00 - total_loss: 67916.3118\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 114s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0063 - factorized_top_k/top_5_categorical_accuracy: 0.0604 - factorized_top_k/top_10_categorical_accuracy: 0.1025 - factorized_top_k/top_50_categorical_accuracy: 0.3002 - factorized_top_k/top_100_categorical_accuracy: 0.4845 - loss: 67566.1293 - regularization_loss: 0.0000e+00 - total_loss: 67566.1293\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 116s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0066 - factorized_top_k/top_5_categorical_accuracy: 0.0619 - factorized_top_k/top_10_categorical_accuracy: 0.1040 - factorized_top_k/top_50_categorical_accuracy: 0.3000 - factorized_top_k/top_100_categorical_accuracy: 0.4850 - loss: 67180.2564 - regularization_loss: 0.0000e+00 - total_loss: 67180.2564\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 110s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0072 - factorized_top_k/top_5_categorical_accuracy: 0.0636 - factorized_top_k/top_10_categorical_accuracy: 0.1061 - factorized_top_k/top_50_categorical_accuracy: 0.3014 - factorized_top_k/top_100_categorical_accuracy: 0.4881 - loss: 66756.0938 - regularization_loss: 0.0000e+00 - total_loss: 66756.0938\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 107s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0078 - factorized_top_k/top_5_categorical_accuracy: 0.0660 - factorized_top_k/top_10_categorical_accuracy: 0.1082 - factorized_top_k/top_50_categorical_accuracy: 0.3043 - factorized_top_k/top_100_categorical_accuracy: 0.4932 - loss: 66293.0220 - regularization_loss: 0.0000e+00 - total_loss: 66293.0220\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 115s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0080 - factorized_top_k/top_5_categorical_accuracy: 0.0685 - factorized_top_k/top_10_categorical_accuracy: 0.1107 - factorized_top_k/top_50_categorical_accuracy: 0.3083 - factorized_top_k/top_100_categorical_accuracy: 0.4997 - loss: 65792.0774 - regularization_loss: 0.0000e+00 - total_loss: 65792.0774\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 108s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0091 - factorized_top_k/top_5_categorical_accuracy: 0.0710 - factorized_top_k/top_10_categorical_accuracy: 0.1138 - factorized_top_k/top_50_categorical_accuracy: 0.3132 - factorized_top_k/top_100_categorical_accuracy: 0.5078 - loss: 65255.2536 - regularization_loss: 0.0000e+00 - total_loss: 65255.2536\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 106s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0095 - factorized_top_k/top_5_categorical_accuracy: 0.0732 - factorized_top_k/top_10_categorical_accuracy: 0.1168 - factorized_top_k/top_50_categorical_accuracy: 0.3193 - factorized_top_k/top_100_categorical_accuracy: 0.5173 - loss: 64684.8040 - regularization_loss: 0.0000e+00 - total_loss: 64684.8040\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 105s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0106 - factorized_top_k/top_5_categorical_accuracy: 0.0761 - factorized_top_k/top_10_categorical_accuracy: 0.1207 - factorized_top_k/top_50_categorical_accuracy: 0.3273 - factorized_top_k/top_100_categorical_accuracy: 0.5271 - loss: 64082.8281 - regularization_loss: 0.0000e+00 - total_loss: 64082.8281\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 106s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0111 - factorized_top_k/top_5_categorical_accuracy: 0.0790 - factorized_top_k/top_10_categorical_accuracy: 0.1245 - factorized_top_k/top_50_categorical_accuracy: 0.3361 - factorized_top_k/top_100_categorical_accuracy: 0.5375 - loss: 63451.1690 - regularization_loss: 0.0000e+00 - total_loss: 63451.1690\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 106s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0122 - factorized_top_k/top_5_categorical_accuracy: 0.0817 - factorized_top_k/top_10_categorical_accuracy: 0.1288 - factorized_top_k/top_50_categorical_accuracy: 0.3464 - factorized_top_k/top_100_categorical_accuracy: 0.5487 - loss: 62791.6925 - regularization_loss: 0.0000e+00 - total_loss: 62791.6925\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 105s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0129 - factorized_top_k/top_5_categorical_accuracy: 0.0854 - factorized_top_k/top_10_categorical_accuracy: 0.1327 - factorized_top_k/top_50_categorical_accuracy: 0.3568 - factorized_top_k/top_100_categorical_accuracy: 0.5597 - loss: 62106.6982 - regularization_loss: 0.0000e+00 - total_loss: 62106.6982\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 106s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0143 - factorized_top_k/top_5_categorical_accuracy: 0.0894 - factorized_top_k/top_10_categorical_accuracy: 0.1376 - factorized_top_k/top_50_categorical_accuracy: 0.3679 - factorized_top_k/top_100_categorical_accuracy: 0.5712 - loss: 61398.9528 - regularization_loss: 0.0000e+00 - total_loss: 61398.9528\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 105s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0151 - factorized_top_k/top_5_categorical_accuracy: 0.0927 - factorized_top_k/top_10_categorical_accuracy: 0.1427 - factorized_top_k/top_50_categorical_accuracy: 0.3803 - factorized_top_k/top_100_categorical_accuracy: 0.5830 - loss: 60671.3817 - regularization_loss: 0.0000e+00 - total_loss: 60671.3817\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 105s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0163 - factorized_top_k/top_5_categorical_accuracy: 0.0964 - factorized_top_k/top_10_categorical_accuracy: 0.1482 - factorized_top_k/top_50_categorical_accuracy: 0.3950 - factorized_top_k/top_100_categorical_accuracy: 0.5958 - loss: 59926.8746 - regularization_loss: 0.0000e+00 - total_loss: 59926.8746\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 105s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0170 - factorized_top_k/top_5_categorical_accuracy: 0.1003 - factorized_top_k/top_10_categorical_accuracy: 0.1531 - factorized_top_k/top_50_categorical_accuracy: 0.4097 - factorized_top_k/top_100_categorical_accuracy: 0.6087 - loss: 59168.2244 - regularization_loss: 0.0000e+00 - total_loss: 59168.2244\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 106s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0181 - factorized_top_k/top_5_categorical_accuracy: 0.1043 - factorized_top_k/top_10_categorical_accuracy: 0.1586 - factorized_top_k/top_50_categorical_accuracy: 0.4251 - factorized_top_k/top_100_categorical_accuracy: 0.6220 - loss: 58398.0384 - regularization_loss: 0.0000e+00 - total_loss: 58398.0384\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 104s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0194 - factorized_top_k/top_5_categorical_accuracy: 0.1083 - factorized_top_k/top_10_categorical_accuracy: 0.1637 - factorized_top_k/top_50_categorical_accuracy: 0.4427 - factorized_top_k/top_100_categorical_accuracy: 0.6350 - loss: 57618.6523 - regularization_loss: 0.0000e+00 - total_loss: 57618.6523\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 105s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0200 - factorized_top_k/top_5_categorical_accuracy: 0.1119 - factorized_top_k/top_10_categorical_accuracy: 0.1695 - factorized_top_k/top_50_categorical_accuracy: 0.4598 - factorized_top_k/top_100_categorical_accuracy: 0.6481 - loss: 56832.0827 - regularization_loss: 0.0000e+00 - total_loss: 56832.0827\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 106s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.0209 - factorized_top_k/top_5_categorical_accuracy: 0.1157 - factorized_top_k/top_10_categorical_accuracy: 0.1752 - factorized_top_k/top_50_categorical_accuracy: 0.4772 - factorized_top_k/top_100_categorical_accuracy: 0.6608 - loss: 56039.9290 - regularization_loss: 0.0000e+00 - total_loss: 56039.9290\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 105s 10s/step - factorized_top_k/top_1_categorical_accuracy: 0.0220 - factorized_top_k/top_5_categorical_accuracy: 0.1195 - factorized_top_k/top_10_categorical_accuracy: 0.1809 - factorized_top_k/top_50_categorical_accuracy: 0.4936 - factorized_top_k/top_100_categorical_accuracy: 0.6733 - loss: 55243.4901 - regularization_loss: 0.0000e+00 - total_loss: 55243.4901\n",
      "5/5 [==============================] - 30s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0017 - factorized_top_k/top_10_categorical_accuracy: 0.0032 - factorized_top_k/top_50_categorical_accuracy: 0.0086 - factorized_top_k/top_100_categorical_accuracy: 0.0141 - loss: 33861.0202 - regularization_loss: 0.0000e+00 - total_loss: 33861.0202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.0017000000225380063,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.0031999999191612005,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.00860000029206276,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.014100000262260437,\n",
       " 'loss': 30709.376953125,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 30709.376953125}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fitting and evaluating\n",
    "\n",
    "### we choose the dimensionality of the query and candicate representation.\n",
    "embedding_dimension = 64\n",
    "\n",
    "## we pass the model, which is the same model we created in the query and candidate tower, into the model\n",
    "item_model = tf.keras.Sequential([\n",
    "                                tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                vocabulary=unique_item_titles, mask_token=None),\n",
    "                                tf.keras.layers.Embedding(len(unique_item_titles) + 1, embedding_dimension)\n",
    "                                ])\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "                                tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                vocabulary=unique_user_ids, mask_token=None),\n",
    "                                # We add an additional embedding to account for unknown tokens.\n",
    "                                tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "                                ])\n",
    "\n",
    "model = RetailModel(user_model, item_model)\n",
    "\n",
    "# a smaller learning rate may make the model move slower and prone to overfitting, so we stick to 0.1\n",
    "# other optimizers, such as SGD and Adam, are listed here https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD())\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "\n",
    "## fit the model with ten epochs\n",
    "model_hist = model.fit(cached_train, epochs=50)\n",
    "\n",
    "#evaluate the model\n",
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d83ceb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 28s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0017 - factorized_top_k/top_10_categorical_accuracy: 0.0032 - factorized_top_k/top_50_categorical_accuracy: 0.0086 - factorized_top_k/top_100_categorical_accuracy: 0.0141 - loss: 33861.0202 - regularization_loss: 0.0000e+00 - total_loss: 33861.0202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.0017000000225380063,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.0031999999191612005,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.00860000029206276,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.014100000262260437,\n",
       " 'loss': 30709.376953125,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 30709.376953125}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afc8cfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'0108775015', b'0108775044', b'0108775051', ..., b'0953450001',\n",
       "       b'0953763001', b'0956217002'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_item_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee76ddfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'00000dbacae5abe5e23885899a1fa44253a17956c6d1c3d25f88aa139fdfc657',\n",
       "       b'0000423b00ade91418cceaf3b26c6af3dd342b51fd051eec9c12fb36984420fa',\n",
       "       b'000058a12d5b43e67d225668fa1f8d618c13dc232df0cad8ffe7ad4a1091e318',\n",
       "       ...,\n",
       "       b'ffffcf35913a0bee60e8741cb2b4e78b8a98ee5ff2e6a1778d0116cffd259264',\n",
       "       b'ffffd7744cebcf3aca44ae7049d2a94b87074c3d4ffe38b2236865d949d4df6a',\n",
       "       b'ffffd9ac14e89946416d80e791d064701994755c3ab686a1eaf3458c36f52241'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_user_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "953f0563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: {customer_id: (), article_id: (), quantity: ()}, types: {customer_id: tf.string, article_id: tf.string, quantity: tf.float32}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47c0f0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x2ea25ee6dc0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(items.batch(100).map(lambda items: (items,model.item_model(items))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d952af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 000231cc9af9e58ab4edc66fbd61da921b144ba85bc1c00d0ae2309531e4c210: [b'0803757001' b'0537116001' b'0697060013' b'0685813002' b'0697564010'\n",
      " b'0730013001' b'0572797002' b'0832331004' b'0853881001' b'0243613004'\n",
      " b'0708755001' b'0720620003']\n"
     ]
    }
   ],
   "source": [
    "j = '000231cc9af9e58ab4edc66fbd61da921b144ba85bc1c00d0ae2309531e4c210'\n",
    "_, titles = index(tf.constant([j]),k=12)\n",
    "print(f\"Recommendations for user %s: {titles[0]}\" %(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd1941b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(e):\n",
    "    return e.decode('UTF-8')\n",
    "def run_f(item):\n",
    "    _, titles = index(tf.constant([item]),k=12)\n",
    "    t = np.array(titles[0])\n",
    "    vfunc = np.vectorize(decoder)\n",
    "    l = vfunc(t)\n",
    "    l = \" \".join(l)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f372f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbd23919eb44f8ba62d73ce922acf3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1371980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission_file = pd.read_csv('h-and-m-personalized-fashion-recommendations/sample_submission.csv')\n",
    "sub_cust = submission_file[\"customer_id\"]\n",
    "sub_df = pd.DataFrame(columns=['Customer_Id', 'Article_Id'])\n",
    "submission_file[\"prediction\"] = submission_file['customer_id'].progress_apply(run_f)\n",
    "submission_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d571bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41466a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
