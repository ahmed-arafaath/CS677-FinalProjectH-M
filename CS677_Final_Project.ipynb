{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405e34ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from typing import Dict, Text\n",
    "from tensorflow import keras\n",
    "import tensorflow_recommenders as tfrs\n",
    "try:\n",
    "    if not tf.config.list_physical_devices('GPU'):\n",
    "        assert tf.__version__ >= \"2.0\"\n",
    "        print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "        if IS_COLAB:\n",
    "            print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "        if IS_KAGGLE:\n",
    "            print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "except:\n",
    "    if not tf.test.is_gpu_available():\n",
    "        assert tf.__version__ >= \"2.0\"\n",
    "        print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "        if IS_COLAB:\n",
    "            print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "        if IS_KAGGLE:\n",
    "            print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "try:\n",
    "    if not tf.config.list_physical_devices('GPU'):\n",
    "        tf.random.set_seed(42)\n",
    "    else:\n",
    "        tf.random.set_random_seed(42)\n",
    "except:\n",
    "    if not tf.test.is_gpu_available():\n",
    "        tf.random.set_seed(42)\n",
    "    else:\n",
    "        tf.random.set_random_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa2f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(file_path, **kwargs):\n",
    "    \n",
    "    art_df_args = dict(filepath_or_buffer=file_path + 'articles.csv',low_memory = False)\n",
    "    if 'art_cols' in kwargs:\n",
    "        art_df_args['usecols']=kwargs['art_cols']\n",
    "    \n",
    "    cust_df_args = dict(filepath_or_buffer=file_path + 'customers.csv', low_memory = False)\n",
    "    if  'cust_cols' in  kwargs:\n",
    "        cust_df_args['usecols']=kwargs['cust_cols']\n",
    "    \n",
    "    trans_df_args= dict(filepath_or_buffer=file_path + 'transactions_train.csv', low_memory = False)\n",
    "    if  'trans_cols' in kwargs:\n",
    "        trans_df_args['usecols']=kwargs['trans_cols']\n",
    "    \n",
    "    art_df = pd.read_csv(**art_df_args)\n",
    "    cust_df = pd.read_csv(**cust_df_args)\n",
    "    trans_df= pd.read_csv(**trans_df_args)\n",
    "    \n",
    "    customer_lookup = cust_df.reset_index().set_index('customer_id')['index'].astype(str).to_dict()\n",
    "    article_lookup =art_df.reset_index().set_index('article_id')['index'].astype(str).to_dict()\n",
    "    \n",
    "    trans_df['user_id']= trans_df['customer_id'].map(customer_lookup)\n",
    "    trans_df['item_id']= trans_df['article_id'].map(article_lookup)\n",
    "    \n",
    "    unique_users = trans_df['user_id'].unique()\n",
    "    unique_items = trans_df['item_id'].unique()\n",
    "    \n",
    "    trans_df = trans_df.drop(columns =['customer_id','article_id'])\n",
    "    \n",
    "    return customer_lookup, article_lookup, trans_df, unique_users, unique_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f6e3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'h-and-m-personalized-fashion-recommendations/'\n",
    "customer_lookup, article_lookup, trans_data, user_vocab, item_vocab = read_files(file_path, cust_cols=['customer_id'], trans_cols= ['customer_id','article_id'])\n",
    "train_size =0.80\n",
    "np.random.seed(1221)\n",
    "train = trans_data[['user_id','item_id']].sample(frac=train_size)\n",
    "temp =  trans_data[['user_id','item_id']].drop(train.index)\n",
    "valid=temp[['user_id','item_id']].sample(frac=0.5)\n",
    "test=temp[['user_id','item_id']].drop(valid.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458f4891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19627965</th>\n",
       "      <td>70577</td>\n",
       "      <td>85494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17303022</th>\n",
       "      <td>1010149</td>\n",
       "      <td>76976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7509776</th>\n",
       "      <td>1345921</td>\n",
       "      <td>47593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22862834</th>\n",
       "      <td>558431</td>\n",
       "      <td>46406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20767652</th>\n",
       "      <td>733097</td>\n",
       "      <td>87565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id item_id\n",
       "19627965    70577   85494\n",
       "17303022  1010149   76976\n",
       "7509776   1345921   47593\n",
       "22862834   558431   46406\n",
       "20767652   733097   87565"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c39e4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>198</td>\n",
       "      <td>47423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>235</td>\n",
       "      <td>43407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>235</td>\n",
       "      <td>12403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>235</td>\n",
       "      <td>1780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>659</td>\n",
       "      <td>36913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id item_id\n",
       "10     198   47423\n",
       "24     235   43407\n",
       "39     235   12403\n",
       "40     235    1780\n",
       "45     659   36913"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d98b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "items = tf.data.Dataset.from_tensor_slices(item_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92f94918",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(\n",
    "        vocabulary = user_vocab, mask_token =None),\n",
    "    tf.keras.layers.Embedding(len(user_vocab)+1, embedding_dimension)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bfd7738",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(\n",
    "        vocabulary = item_vocab, mask_token =None),\n",
    "    tf.keras.layers.Embedding(len(item_vocab)+1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b06b9e0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'items' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SAJIN~1.LAP\\AppData\\Local\\Temp/ipykernel_15188/1364299215.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m metrics = tfrs.metrics.FactorizedTopK(\n\u001b[1;32m----> 2\u001b[1;33m     candidates=items.batch(256).map(item_model))\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRetrieval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'items' is not defined"
     ]
    }
   ],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=items.batch(256).map(item_model))\n",
    "\n",
    "task = tfrs.tasks.Retrieval(metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a07155",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserItemModel(tfrs.Model):\n",
    "    \n",
    "    def __init__(self, user_model, item_model):\n",
    "        super().__init__()\n",
    "        self.user_model : tf.keras.Model = user_model\n",
    "        self.item_model : tf.keras.Model = item_model\n",
    "        self.task : tf.keras.layers.Layer = task\n",
    "            \n",
    "    def compute_loss(self,features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        \n",
    "        user_embeddings = self.user_model(features['user_id'])\n",
    "        positive_item_embeddings = self.item_model(features['item_id'])\n",
    "        \n",
    "        return self.task(user_embeddings,positive_item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8253b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UserItemModel(user_model, item_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99accad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.batch(8192).cache()\n",
    "cached_valid = valid.batch(4096).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819c19d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(cached_train, epochs=10,validation_data=cached_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
